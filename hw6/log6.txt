Myanna Harris
Kristina Spring

HW 6

Log

Step 1:
- Reusing old code was helpful
- Had to edit the attribute selector method
- Made a method to do confusion matrices for Random Forest

Step 2:
- Used new random, stratified test and remainder set for both random forest and 
    the compared noremal decision tree
- Used a flag to tell the difference between datasets since each has different 
    types of classifier that may or may not be used as indices
- Works fairly fast compared to past projects

Step 3:
- Tried:
    N:  20  40  60  40  40  40  100 70  60  60  60
    M:  7   7   7   20  7   2   7   7   15  10  7
    F:  2   2   2   2   4   2   2   2   2   2   3

- Increasing N to 40 and leaving others the same increased accuracy on the 
    Auto dataset

- Increasing N to 60 and leaving others the same increased accuracy on the 
    Auto dataset more (usually above 60)
    
- Increasing N to 40 and increasing M to 20 didn't increase the accuracy much, 
    if at all

- Increasing N to 40 and increasing F to 4 didn't increase the accuracy much

- Increasing N to 40 and decreasing M to 2 Made it worse

- Increasing N to 100 Made it worse

- Increasing N to 100 made it a little bit worse

- Most changes mainly affected Auto and not as much Titanic
    
- The best results were from:
    N:  60
    M:  7
    F:  2

===========================================
STEP 2: Titanic Dataset
===========================================
Random Forest (On Titanic) : accuracy: 0.791836734694, error rate: 0.208163265306

Random Forest (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            91    147       91            24.7798
Yes            6    491      491            45.1788
==========  ====  =====  =======  =================

Normal Decision Tree (On Titanic) : accuracy: 0.791836734694, error rate: 0.208163265306

Normal Decision Tree (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            91    147       91            24.7798
Yes            6    491      491            45.1788
==========  ====  =====  =======  =================

===========================================
STEP 2: Auto Dataset
===========================================
Random Forest (On Auto) : accuracy: 0.576576576577, error rate: 0.423423423423

Random Forest (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1    9    0    3    0    0    0    0    0    0     0        9            9.375
    2    3    2    1    1    0    0    0    0    0     0        2            5.32319
    3    2    0    6    4    0    0    0    0    0     0        6            8.82353
    4    1    0    3   10    7    0    0    0    0     0       10           12.7196
    5    0    0    1    0   17    1    1    1    0     0       17           14.2914
    6    0    0    0    0    6    6    2    1    0     0        6            9.83607
    7    0    0    0    0    1    0    8    3    0     0        8            9.23077
    8    0    0    0    0    0    1    2    5    1     0        5            7.1885
    9    0    0    0    0    0    0    0    1    1     0        1            1.88679
   10    0    0    0    0    0    0    0    0    0     0        0            0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

Normal Decision Tree (On Auto) : accuracy: 0.423423423423, error rate: 0.576576576577

Normal Decision Tree (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1    9    0    3    0    0    0    0    0    0     0        9            75
    2    3    2    1    1    0    0    0    0    0     0        2            28.5714
    3    2    0    5    3    2    0    0    0    0     0        5            41.6667
    4    1    0    3    5   12    0    0    0    0     0        5            23.8095
    5    0    0    1    4   13    1    1    1    0     0       13            61.9048
    6    0    0    0    0    9    3    2    1    0     0        3            20
    7    0    0    0    0    2    1    4    3    2     0        4            33.3333
    8    0    0    0    0    0    1    2    5    1     0        5            55.5556
    9    0    0    0    0    0    0    0    1    1     0        1            50
   10    0    0    0    0    0    0    0    0    0     0        0             0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

kristina@Jade:~/Dropbox/stuff/fall 2016$ python hw6.py
===========================================
STEP 2: Titanic Dataset
===========================================
Random Forest (On Titanic) : accuracy: 0.789115646259, error rate: 0.210884353741

Random Forest (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            90    148       90            24.6026
Yes            7    490      490            45.1367
==========  ====  =====  =======  =================

Normal Decision Tree (On Titanic) : accuracy: 0.789115646259, error rate: 0.210884353741

Normal Decision Tree (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            90    148       90            24.6026
Yes            7    490      490            45.1367
==========  ====  =====  =======  =================

===========================================
STEP 2: Auto Dataset
===========================================
Random Forest (On Auto) : accuracy: 0.612612612613, error rate: 0.387387387387

Random Forest (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1    9    1    0    2    0    0    0    0    0     0        9            9.375
    2    2    2    1    2    0    0    0    0    0     0        2            5.32319
    3    1    0    8    3    0    0    0    0    0     0        8            9.23077
    4    0    0    2   13    6    0    0    0    0     0       13           13.5551
    5    0    0    0    3   14    1    3    0    0     0       14           13.7705
    6    0    0    0    0    3    7    3    2    0     0        7           10.1942
    7    0    0    0    0    1    0    9    2    0     0        9            9.375
    8    0    0    0    0    0    0    3    5    1     0        5            7.1885
    9    0    0    0    0    0    0    0    1    1     0        1            1.88679
   10    0    0    0    0    0    0    0    0    0     0        0            0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

Normal Decision Tree (On Auto) : accuracy: 0.396396396396, error rate: 0.603603603604

Normal Decision Tree (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1    9    1    2    0    0    0    0    0    0     0        9            75
    2    3    1    3    0    0    0    0    0    0     0        1            14.2857
    3    1    0    7    4    0    0    0    0    0     0        7            58.3333
    4    0    0    6    5   10    0    0    0    0     0        5            23.8095
    5    0    0    1    4    8    5    3    0    0     0        8            38.0952
    6    0    0    0    0    2    4    2    6    1     0        4            26.6667
    7    0    0    0    0    1    3    5    1    2     0        5            41.6667
    8    0    0    0    0    0    1    2    4    2     0        4            44.4444
    9    0    0    0    0    0    0    0    1    1     0        1            50
   10    0    0    0    0    0    0    0    0    0     0        0             0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

kristina@Jade:~/Dropbox/stuff/fall 2016$ python hw6.py
===========================================
STEP 2: Titanic Dataset
===========================================
Random Forest (On Titanic) : accuracy: 0.808163265306, error rate: 0.191836734694

Random Forest (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No           102    136      102            26.6418
Yes            5    492      492            45.2208
==========  ====  =====  =======  =================

Normal Decision Tree (On Titanic) : accuracy: 0.808163265306, error rate: 0.191836734694

Normal Decision Tree (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No           102    136      102            26.6418
Yes            5    492      492            45.2208
==========  ====  =====  =======  =================

===========================================
STEP 2: Auto Dataset
===========================================
Random Forest (On Auto) : accuracy: 0.603603603604, error rate: 0.396396396396

Random Forest (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1    9    3    0    0    0    0    0    0    0     0        9            9.375
    2    5    1    1    0    0    0    0    0    0     0        1            4.48718
    3    4    0    4    4    0    0    0    0    0     0        4            8.10811
    4    3    0    0   11    7    0    0    0    0     0       11           13.0361
    5    0    0    1    2   15    1    2    0    0     0       15           13.9628
    6    0    0    0    0    3    9    2    1    0     0        9           10.7143
    7    0    0    0    0    1    1   10    0    0     0       10            9.49367
    8    0    0    0    0    0    1    0    7    1     0        7            7.46445
    9    0    0    0    0    0    0    0    1    1     0        1            1.88679
   10    0    0    0    0    0    0    0    0    0     0        0            0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

Normal Decision Tree (On Auto) : accuracy: 0.36036036036, error rate: 0.63963963964

Normal Decision Tree (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1    6    3    0    3    0    0    0    0    0     0        6            50
    2    2    1    1    3    0    0    0    0    0     0        1            14.2857
    3    2    0    3    7    0    0    0    0    0     0        3            25
    4    2    0    3    9    5    1    1    0    0     0        9            42.8571
    5    0    0    1    5   11    2    1    1    0     0       11            52.381
    6    0    0    0    0    6    2    5    1    1     0        2            13.3333
    7    0    0    0    0    3    1    3    2    3     0        3            25
    8    0    0    0    0    0    0    4    4    1     0        4            44.4444
    9    0    0    0    0    0    0    0    1    1     0        1            50
   10    0    0    0    0    0    0    0    0    0     0        0             0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

kristina@Jade:~/Dropbox/stuff/fall 2016$ python hw6.py
===========================================
STEP 2: Titanic Dataset
===========================================
Random Forest (On Titanic) : accuracy: 0.779591836735, error rate: 0.220408163265

Random Forest (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            84    154       84            23.51
Yes            8    489      489            45.0945
==========  ====  =====  =======  =================

Normal Decision Tree (On Titanic) : accuracy: 0.779591836735, error rate: 0.220408163265

Normal Decision Tree (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            84    154       84            23.51
Yes            8    489      489            45.0945
==========  ====  =====  =======  =================

===========================================
STEP 2: Auto Dataset
===========================================
Random Forest (On Auto) : accuracy: 0.63963963964, error rate: 0.36036036036

Random Forest (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1   12    0    0    0    0    0    0    0    0     0       12            9.67742
    2    5    2    0    0    0    0    0    0    0     0        2            5.32319
    3    4    1    7    0    0    0    0    0    0     0        7            9.05172
    4    0    0    4   11    6    0    0    0    0     0       11           13.0361
    5    0    0    0    0   20    0    1    0    0     0       20           14.6802
    6    0    0    0    0    5    7    2    1    0     0        7           10.1942
    7    0    0    0    0    3    1    5    3    0     0        5            8.52273
    8    0    0    0    0    0    0    2    6    1     0        6            7.34694
    9    0    0    0    0    0    0    1    0    1     0        1            1.88679
   10    0    0    0    0    0    0    0    0    0     0        0            0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

Normal Decision Tree (On Auto) : accuracy: 0.477477477477, error rate: 0.522522522523

Normal Decision Tree (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1   12    0    0    0    0    0    0    0    0     0       12           100
    2    7    0    0    0    0    0    0    0    0     0        0             0
    3    6    0    4    1    1    0    0    0    0     0        4            33.3333
    4    1    0    2   12    6    0    0    0    0     0       12            57.1429
    5    0    0    0    7   12    1    1    0    0     0       12            57.1429
    6    0    0    0    1    6    5    2    1    0     0        5            33.3333
    7    0    0    0    0    3    2    4    3    0     0        4            33.3333
    8    0    0    0    0    1    0    2    3    3     0        3            33.3333
    9    0    0    0    0    0    0    1    0    1     0        1            50
   10    0    0    0    0    0    0    0    0    0     0        0             0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

kristina@Jade:~/Dropbox/stuff/fall 2016$ python hw6.py
===========================================
STEP 2: Titanic Dataset
===========================================
Random Forest (On Titanic) : accuracy: 0.774149659864, error rate: 0.225850340136

Random Forest (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            85    153       85            23.6957
Yes           13    484      484            44.882
==========  ====  =====  =======  =================

Normal Decision Tree (On Titanic) : accuracy: 0.768707482993, error rate: 0.231292517007

Normal Decision Tree (On Titanic) :
==========  ====  =====  =======  =================
Survival      No    Yes    Total    Recognition (%)
==========  ====  =====  =======  =================
No            90    148       90            24.6026
Yes           22    475      475            44.4934
==========  ====  =====  =======  =================

===========================================
STEP 2: Auto Dataset
===========================================
Random Forest (On Auto) : accuracy: 0.612612612613, error rate: 0.387387387387

Random Forest (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1   11    0    1    0    0    0    0    0    0     0       11            9.59302
    2    6    0    1    0    0    0    0    0    0     0        0            0
    3    3    1    6    2    0    0    0    0    0     0        6            8.82353
    4    0    0    4   13    4    0    0    0    0     0       13           13.5551
    5    1    0    0    3   17    0    0    0    0     0       17           14.2914
    6    0    0    0    0    5    6    3    1    0     0        6            9.83607
    7    0    0    0    0    2    1    6    2    1     0        6            8.82353
    8    0    0    0    0    0    2    0    7    0     0        7            7.46445
    9    0    0    0    0    0    0    0    0    2     0        2            1.92308
   10    0    0    0    0    0    0    0    0    0     0        0            0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

Normal Decision Tree (On Auto) : accuracy: 0.432432432432, error rate: 0.567567567568

Normal Decision Tree (On Auto) :
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================
    1   11    0    1    0    0    0    0    0    0     0       11            91.6667
    2    6    0    1    0    0    0    0    0    0     0        0             0
    3    3    2    6    1    0    0    0    0    0     0        6            50
    4    0    2    6    7    6    0    0    0    0     0        7            33.3333
    5    1    0    1    7    8    4    0    0    0     0        8            38.0952
    6    0    0    0    1    5    5    2    2    0     0        5            33.3333
    7    0    0    0    0    2    3    4    3    0     0        4            33.3333
    8    0    0    0    0    0    2    0    5    2     0        5            55.5556
    9    0    0    0    0    0    0    0    0    2     0        2           100
   10    0    0    0    0    0    0    0    0    0     0        0             0
=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================

Step 4:
- Tried:
    N:  20  60  60  60  10  1000
    M:  7   7   30  7   3   10  
    F:  2   2   2   5   2   2   

- Increasing N to 60 and leaving others the same increased accuracy on the
    Wisconsin dataset
    
- Increasing N to 60 and M to 30 increased the accuracy even more (>96%)

- Increasing N to 60 and F to 5 didn't increase the accuracy much, if at all

- Decreasing N to 10 and M to 3 lowered accuracy, though surprisingly not much,
    usually accuracy was still greater than 89%
    
- Increasing N to 1000 and M to 10 didn't increase accuracy much, if at all

- The best results were from:
    N:  60
    M:  30
    F:  2
    
===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.956331877729, error rate: 0.0436681222707

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          145            4      145            37.0545
malignant         6           74       74            30.0203
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.92576419214, error rate: 0.0742358078603

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          144            5      144            36.9568
malignant        12           68       68            29.1845
=========  ========  ===========  =======  =================


===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.943231441048, error rate: 0.056768558952

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          147            2      147            37.2475
malignant        11           69       69            29.3305
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.899563318777, error rate: 0.100436681223

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          133           16      133            35.8238
malignant         7           73       73            29.8874
=========  ========  ===========  =======  =================


===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.96943231441, error rate: 0.0305676855895

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          146            3      146            37.1514
malignant         4           76       76            30.2789
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.938864628821, error rate: 0.061135371179

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          145            4      145            37.0545
malignant        10           70       70            29.4737
=========  ========  ===========  =======  =================


===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.960698689956, error rate: 0.0393013100437

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          145            4      145            37.0545
malignant         5           75       75            30.1508
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.930131004367, error rate: 0.0698689956332

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          145            4      145            37.0545
malignant        12           68       68            29.1845
=========  ========  ===========  =======  =================


===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.960698689956, error rate: 0.0393013100437

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          147            2      147            37.2475
malignant         7           73       73            29.8874
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.934497816594, error rate: 0.0655021834061

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          146            3      146            37.1514
malignant        12           68       68            29.1845
=========  ========  ===========  =======  =================


===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.938864628821, error rate: 0.061135371179

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          143            6      143            36.8582
malignant         8           72       72            29.7521
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.899563318777, error rate: 0.100436681223

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          142            7      142            36.7588
malignant        16           64       64            28.5714
=========  ========  ===========  =======  =================


===========================================
STEP 3: Wisconsin Dataset
===========================================
Random Forest (On Wisconsin) : accuracy: 0.965065502183, error rate: 0.0349344978166

Random Forest (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          147            2      147            37.2475
malignant         6           74       74            30.0203
=========  ========  ===========  =======  =================

Normal Decision Tree (On Wisconsin) : accuracy: 0.92576419214, error rate: 0.0742358078603

Normal Decision Tree (On Wisconsin) :
=========  ========  ===========  =======  =================
Tumor        benign    malignant    Total    Recognition (%)
=========  ========  ===========  =======  =================
benign          146            3      146            37.1514
malignant        14           66       66            28.884
=========  ========  ===========  =======  =================
